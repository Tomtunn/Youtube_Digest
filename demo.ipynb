{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from transformers import BartTokenizer, BartForConditionalGeneration\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "from tqdm.auto import tqdm\n",
    "import gradio as gr\n",
    "import torch\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.38.1'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MVP concept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figure/figure2.png\" alt=\"drawing\" width=\"1000\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max number of tokens: 1024\n",
      "Number of parameters: 406290432\n"
     ]
    }
   ],
   "source": [
    "# load model and tokenizer\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\" \n",
    "model = BartForConditionalGeneration.from_pretrained(\"facebook/bart-large-cnn\").to(device)\n",
    "tokenizer = BartTokenizer.from_pretrained(\"facebook/bart-large-cnn\")\n",
    "\n",
    "link = \"https://www.youtube.com/watch?v=z4fai9N8HtQ\" # link to the video\n",
    "# count model parameters\n",
    "num_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Max number of tokens: {model.config.max_position_embeddings}\")\n",
    "print(f\"Number of parameters: {num_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figure/figure1.png\" alt=\"drawing\" width=\"1000\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(tokens, model, max_summary_length=512, device=\"cpu\"):\n",
    "    \"\"\"\n",
    "    tokens: input token (tensor of token)\n",
    "    max_summary_length: maximum number of tokens in summary (int)\n",
    "    device: device to run model (str)\n",
    "    \n",
    "    return summarize input text using model (str)\n",
    "    \"\"\"\n",
    "    token_input = tokens.to(device)\n",
    "    model = model.to(device)\n",
    "    summary_ids = model.generate(token_input, min_length=int(max_summary_length//5), max_length=max_summary_length, num_beams=4,  early_stopping=True)\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    return summary\n",
    "\n",
    "def split_token_chunks(text, tokenizer, max_tokens=1024, overlap=0.2, device=\"cpu\"):\n",
    "    \"\"\"\n",
    "    text: input text (str)\n",
    "    max_tokens: maximum number of tokens per chunk (int)\n",
    "    overlap: number of overlapping tokens between chunks (int)\n",
    "    device: device to run model (str)\n",
    "    \n",
    "    create overlapping token chunks from input\n",
    "    \n",
    "    return: list of token chunks (list of tensor)\n",
    "    \"\"\"\n",
    "    tokens = tokenizer(\"summarize: \" + text, return_tensors=\"pt\")[\"input_ids\"].to(device)\n",
    "    token_chunks = [tokens[:, i:i+max_tokens] for i in range(0, tokens.shape[1], max_tokens-int(max_tokens*overlap))] # split token into chunks\n",
    "    return token_chunks\n",
    "    \n",
    "def summarize_long_text(text, max_summary_length=512, level=0, max_token_length=1024, device=\"cpu\"):\n",
    "    \"\"\"\n",
    "    text: input text (str)\n",
    "    max_summary_length: maximum number of tokens in summary (int)\n",
    "    level: level of recursion (int)\n",
    "    max_token_length: maximum number of tokens per chunk (int)\n",
    "    device: device to run model (str)\n",
    "\n",
    "    recursively summarize long text by splitting into chunks\n",
    "    \n",
    "    return summarize input text using model (str)\n",
    "    \"\"\"\n",
    "    level = level + 1\n",
    "    print(f\"Level: {level}\")\n",
    "    token_chunks = split_token_chunks(text, tokenizer, device=device)\n",
    "    summary_ls = []\n",
    "    for token_chunk in tqdm(token_chunks):\n",
    "        summary = summarize(token_chunk, model, max_summary_length=int(max_summary_length//3), device=device)\n",
    "        summary_ls.append(summary)\n",
    "    summary_concat = \" \".join(summary_ls)\n",
    "    tokens_summary_concat = tokenizer(summary_concat, return_tensors=\"pt\")[\"input_ids\"]\n",
    "    \n",
    "    if tokens_summary_concat.shape[1] > max_token_length:\n",
    "        return summarize_long_text(summary_concat, max_summary_length=max_summary_length, level=level,  device=device)\n",
    "    if level > 100:\n",
    "        print(\"Level > 100, return summary_concat\")\n",
    "        return summary_concat\n",
    "    else:\n",
    "        final_summary = summarize(tokens_summary_concat, model, max_summary_length=max_summary_length, device=device)\n",
    "        return final_summary\n",
    "\n",
    "def get_transcript(video_link):\n",
    "    \"\"\"\n",
    "    video_link: youtube video link (str)\n",
    "    \n",
    "    return transcript of the video (str)\n",
    "    \"\"\"\n",
    "    video_id = video_link.split(\"v=\")[1]\n",
    "    eng_transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
    "    transcript = \" \".join([line['text'] for line in eng_transcript])\n",
    "    return transcript  \n",
    "\n",
    "def get_video_summary(video_link, max_summary_length=512, device=\"cpu\"):\n",
    "    \"\"\"\n",
    "    video_link: youtube video link (str)\n",
    "    \n",
    "    return transcript of the video (str)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        transcript = get_transcript(video_link)\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return \"Error: No transcript found\"\n",
    "    summary = summarize_long_text(transcript, max_summary_length=max_summary_length, device=device)\n",
    "    return summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2847 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Level: 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f343535e4a44c08bb46dd03bcc01d7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "video_summary = get_video_summary(link, max_summary_length=512, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " AI video boom was all started thanks to the release of cing published by a Chinese social media company called quiso which is similar to Tik Tok. Luma dream machine which was released 5 days after cling was another big but pleasant surprise too. These models are roughly equally good and equally bad at the same time they are all still terrible at Anatomy well it's still expected as AI image Generations still can't handle the anatomy well either. These AI video generators are still far from being World simulators but creative wise it still has some pretty interesting touch it can provide.\n"
     ]
    }
   ],
   "source": [
    "print(video_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7861\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo = gr.Interface(\n",
    "    fn=lambda text, max_length: get_video_summary(text, max_length, device=device), \n",
    "    inputs=[\"text\", \n",
    "            gr.Slider(100, 5000, value=512, label=\"Max Summary Length\", step=100)],\n",
    "    outputs=\"text\",\n",
    "    title=\"Video Summarization\", \n",
    "    description=\"Paste youtube url below\")\n",
    "\n",
    "demo.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
